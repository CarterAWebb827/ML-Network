{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qedGtEEkFYtg"
   },
   "source": [
    "# Machine Learning Network Anomaly Analysis and Prediction for CPE 400\n",
    "****\n",
    "## This is my final project. In this project, I am analyzing the network data through the many subplots. After analysis, I provide different predictions of the data in the dataset by using different data algorithms. This includes Naive Bayes, Logistic Regression, Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uczq1cowBNW"
   },
   "source": [
    "## First we need to set up the dataset for training\n",
    "****\n",
    "**I am using a dataset from kaggle, therefore, i first need to set up and upload by key credentials, then i can start with the dataset**\n",
    "\n",
    "**Here is the dataset i am using: https://www.kaggle.com/datasets/ernie55ernie/improved-cicids2017-and-csecicids2018/data**\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "xJEp4Cb4vxtX",
    "outputId": "4f7990ae-2f35-467b-e817-6aa596e94f96"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Are you using Google Colab (y/n):  n\n",
      "Do you need to download the datasets (y/n)?:  n\n",
      "Enter dataset selection (0: Both, 1: CICIDS2017, 2: CSECICIDS2018):  1\n",
      "Process any data (y/n)?:  n\n",
      "How many CPU cores would you like to use?:  5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import subprocess\n",
    "\n",
    "isUsingColab = input(\"Are you using Google Colab (y/n): \").lower().strip() == \"y\"\n",
    "# Ask the user whether they need to download the datasets\n",
    "askDownload = input(\"Do you need to download the datasets (y/n)?: \").lower().strip() == \"y\"\n",
    "mode = int(input(\"Enter dataset selection (0: Both, 1: CICIDS2017, 2: CSECICIDS2018): \"))\n",
    "askPlot = input(\"Process any data (y/n)?: \").lower().strip() == \"y\"\n",
    "askCPU = int(input(\"How many CPU cores would you like to use?: \"))\n",
    "\n",
    "if (askPlot):\n",
    "  askGraph = input(\"Process subplot data (y/n)?: \").lower().strip() == \"y\"\n",
    "\n",
    "if isUsingColab:\n",
    "    if askDownload:\n",
    "        from google.colab import files\n",
    "        \n",
    "        # Upload the Kaggle API credentials\n",
    "        print(\"Please upload your kaggle.json file:\")\n",
    "        uploaded = files.upload()  # Upload file in Colab\n",
    "        \n",
    "        # Save the uploaded kaggle.json file in the appropriate directory\n",
    "        for filename in uploaded.keys():\n",
    "            print(f'User uploaded file \"{filename}\" with length {len(uploaded[filename])} bytes')\n",
    "        \n",
    "        # Create the .kaggle directory if it doesn\"t exist\n",
    "        kaggleDir = os.path.expanduser(\"~/.kaggle\")\n",
    "        if not os.path.exists(kaggleDir):\n",
    "            os.makedirs(kaggleDir)\n",
    "        \n",
    "        # Define the path where kaggle.json will be copied\n",
    "        kaggleKeyDest = os.path.join(kaggleDir, \"kaggle.json\")\n",
    "        \n",
    "        # Save kaggle.json file to the destination\n",
    "        with open(kaggleKeyDest, \"wb\") as kaggleFile:\n",
    "            kaggleFile.write(uploaded[filename])\n",
    "        \n",
    "        # Set the correct permissions for the file (Unix-based systems)\n",
    "        os.chmod(kaggleKeyDest, 0o600)\n",
    "        \n",
    "        # Check if the datasets already exist before downloading\n",
    "        dataset2017 = \"CICIDS2017_improved\"\n",
    "        dataset2018 = \"CSECICIDS2018_improved\"\n",
    "        if not os.path.exists(dataset2017) or not os.path.exists(dataset2018):\n",
    "            # Install Kaggle API using pip\n",
    "            subprocess.run([\"python\", \"-m\", \"pip\", \"install\", \"kaggle\"], check=True)\n",
    "        \n",
    "            # Define the dataset\n",
    "            dataset = \"ernie55ernie/improved-cicids2017-and-csecicids2018\"\n",
    "        \n",
    "            # Download the dataset using the Kaggle API\n",
    "            subprocess.run([\"kaggle\", \"datasets\", \"download\", \"-d\", dataset], check=True)\n",
    "        \n",
    "            # Unzip the downloaded dataset\n",
    "            zipFile = \"improved-cicids2017-and-csecicids2018.zip\"\n",
    "            with zipfile.ZipFile(zipFile, \"r\") as zipRef:\n",
    "              print(\"File is being extracted\")\n",
    "              zipRef.extractall()\n",
    "        \n",
    "        # Delete the zip file after extraction\n",
    "            os.remove(zipFile)\n",
    "            print(f\"Dataset downloaded, extracted, and zip file {zipFile} deleted.\")\n",
    "        else:\n",
    "            print(f\"Dataset already exists in the {dataset2017} and {dataset2018} folders. No download needed.\")\n",
    "else:\n",
    "    if askDownload:\n",
    "        # Ask user to manually place kaggle.json in the correct directory\n",
    "        kaggleDir = os.path.expanduser(\"~/.kaggle\")\n",
    "        kaggleKeyDest = os.path.join(kaggleDir, \"kaggle.json\")\n",
    "        \n",
    "        if not os.path.exists(kaggleKeyDest):\n",
    "            print(f\"Please manually place the kaggle.json file in {kaggleDir}\")\n",
    "\n",
    "        # Check if the datasets already exist before downloading\n",
    "        dataset2017 = \"CICIDS2017_improved\"\n",
    "        dataset2018 = \"CSECICIDS2018_improved\"\n",
    "        if not os.path.exists(dataset2017) or not os.path.exists(dataset2018):\n",
    "            # Install Kaggle API using pip\n",
    "            subprocess.run([\"python\", \"-m\", \"pip\", \"install\", \"kaggle\"], check=True)\n",
    "\n",
    "            # Define the dataset\n",
    "            dataset = \"ernie55ernie/improved-cicids2017-and-csecicids2018\"\n",
    "\n",
    "            # Download the dataset using the Kaggle API\n",
    "            subprocess.run([\"kaggle\", \"datasets\", \"download\", \"-d\", dataset], check=True)\n",
    "\n",
    "            # Unzip the downloaded dataset\n",
    "            zipFile = \"improved-cicids2017-and-csecicids2018.zip\"\n",
    "            with zipfile.ZipFile(zipFile, \"r\") as zipRef:\n",
    "                print(\"File is being extracted\")\n",
    "                zipRef.extractall()\n",
    "\n",
    "            # Delete the zip file after extraction\n",
    "            os.remove(zipFile)\n",
    "            print(f\"Dataset downloaded, extracted, and zip file {zipFile} deleted.\")\n",
    "        else:\n",
    "            print(f\"Dataset already exists in the {dataset2017} and {dataset2018} folders. No download needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6FK7Aj9CZ0n"
   },
   "source": [
    "## Next, I will choose what dataset(s) I would like to use\n",
    "****\n",
    "**I am loading the dataset(s) into a variable - dfList**\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iVy9hW0qRMKz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading CSV files: 100%|█████████████████████████████████████████████████████████████████| 5/5 [00:09<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Reading CSV file(s), Starting Encoding...\n",
      "Finished Encoding.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gc\n",
    "\n",
    "dfList = []\n",
    "labels = []\n",
    "\n",
    "projectDir = os.getcwd()\n",
    "pathToCSV2017 = os.path.join(projectDir, \"CICIDS2017_improved\")\n",
    "pathToCSV2018 = os.path.join(projectDir, \"CSECICIDS2018_improved\")\n",
    "\n",
    "# Based on the mode, decide which dataset(s) to include\n",
    "csvCombined = []\n",
    "if mode == 0:\n",
    "  # Load both datasets\n",
    "  csv2017 = glob.glob(os.path.join(pathToCSV2017, \"*.csv\"))\n",
    "  csv2018 = glob.glob(os.path.join(pathToCSV2018, \"*.csv\"))\n",
    "  csvCombined = csv2017 + csv2018\n",
    "elif mode == 1:\n",
    "  # Load only CICIDS2017 dataset\n",
    "  csv2017 = glob.glob(os.path.join(pathToCSV2017, \"*.csv\"))\n",
    "  csvCombined = csv2017\n",
    "elif mode == 2:\n",
    "  # Load only CSECICIDS2018 dataset\n",
    "  csv2018 = glob.glob(os.path.join(pathToCSV2018, \"*.csv\"))\n",
    "  csvCombined = csv2018\n",
    "else:\n",
    "  raise ValueError(\"Invalid mode selected. Choose 0 (both), 1 (CICIDS2017), or 2 (CSECICIDS2018).\")\n",
    "\n",
    "# Iterate over files with tqdm for progress tracking\n",
    "for file in tqdm(csvCombined, desc=\"Reading CSV files\"):\n",
    "  # Read the CSV file into a DataFrame and append to the list\n",
    "  df = pd.read_csv(file)\n",
    "  dfList.append(df)\n",
    "\n",
    "print(\"Finished Reading CSV file(s), Starting Encoding...\")\n",
    "# Encode labels for each DataFrame\n",
    "aLabels = pd.concat([df[\"Label\"] for df in dfList]).unique()\n",
    "le = LabelEncoder()\n",
    "le.fit(aLabels)\n",
    "for idx in range(len(dfList)):\n",
    "  oLabels = dfList[idx][\"Label\"].unique()\n",
    "  eLabels = le.transform(dfList[idx][\"Label\"])\n",
    "\n",
    "  labelMap = {original: le.transform([original])[0] for original in oLabels}\n",
    "  labels.append(labelMap)\n",
    "\n",
    "  #print (labelMap)\n",
    "\n",
    "  dfList[idx][\"Label\"] = eLabels\n",
    "\n",
    "print(\"Finished Encoding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezyPoI5yCZBq"
   },
   "source": [
    "## After that, I make a function to plot all of the unprocessed data for analysis\n",
    "****\n",
    "**I save this data to the Figures folder to be downloaded later**\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cxsTDfUdA0jU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "def plotData(columns, xlabel, ylabel, sOn, labelMap):\n",
    "  print(\"Mapping Colors\")\n",
    "  numColors = 27\n",
    "  cmap = plt.colormaps.get_cmap(\"tab20\")\n",
    "  colors = cmap(np.linspace(0, 1, numColors))\n",
    "\n",
    "  if not os.path.exists(\"Figures\"):\n",
    "    os.makedirs(\"Figures\")\n",
    "\n",
    "  if sOn:\n",
    "    if not os.path.exists(\"Figures/SubPlots\"):\n",
    "      os.makedirs(\"Figures/SubPlots\")\n",
    "\n",
    "    print(\"Enumerating through our DataFrame List to Plot Data...\")\n",
    "    # Loop through each DataFrame and each column\n",
    "    for dfIdx, df in enumerate(dfList):\n",
    "      df = df.dropna()  # Removes rows with NaN values\n",
    "      for colIdx, col in enumerate(columns):\n",
    "        # Create a new figure for each dataset and column\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))  # Adjust size if necessary\n",
    "\n",
    "        # Plot the data\n",
    "        ax.plot(df.index, df[col], label=f\"{col} (Dataset {dfIdx + 1})\", color=colors[(dfIdx + colIdx) % numColors], linestyle=\"-\", linewidth=1)\n",
    "\n",
    "        # Set labels and title for each individual plot\n",
    "        ax.set_title(f\"{col} - Dataset {dfIdx + 1}\", fontsize=12)\n",
    "        ax.set_xlabel(xlabel, fontsize=10)\n",
    "        ax.set_ylabel(ylabel, fontsize=10)\n",
    "        ax.grid(True, linestyle=\":\", linewidth=0.7, color=\"grey\")\n",
    "\n",
    "        # Adjust layout to avoid overlapping elements\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save each plot with a unique filename\n",
    "        plt.savefig(f\"Figures/SubPlots/Dataset{dfIdx+1}_{col}.png\")\n",
    "        plt.close(fig)  # Close the figure after saving to avoid memory buildup\n",
    "\n",
    "  if not os.path.exists(\"Figures/Histograms\"):\n",
    "    os.makedirs(\"Figures/Histograms\")\n",
    "\n",
    "  print(\"Finished Subplots, Enumerating Data to Plot Histograms...\")\n",
    "  for dfIdx, df in enumerate(dfList):\n",
    "    # Get numerical columns excluding \"Label\" and \"id\" or any non-numeric columns\n",
    "    numericCols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    numericCols.remove(\"Label\")  # Remove Label\n",
    "\n",
    "    for col in numericCols:\n",
    "      plt.figure(figsize=(15, 15))\n",
    "\n",
    "      # Initialize an empty list to hold average values for each label\n",
    "      averages = []\n",
    "\n",
    "      # Plot histogram for each label type\n",
    "      for label in df[\"Label\"].unique():\n",
    "        # Get data for the current label\n",
    "        data = df[df[\"Label\"] == label][col]\n",
    "        # Remove NaN and inf values from the data\n",
    "        data = data[np.isfinite(data)]\n",
    "\n",
    "        if len(data) > 0:  # Check if there is data to plot\n",
    "            avgVal = data.mean()\n",
    "\n",
    "            oLabel = next((orig for orig, enc in labelMap[dfIdx].items() if enc == label), str(label))\n",
    "\n",
    "            averages.append((oLabel, avgVal))\n",
    "\n",
    "            # Use colormap to get color for the label\n",
    "            plt.hist(data, bins=30, alpha=0.5, color=colors[label],\n",
    "                    label=f\"{oLabel} (Avg: {avgVal:.2f})\", edgecolor=\"black\")\n",
    "\n",
    "      # Set titles and labels\n",
    "      plt.title(f\"Histogram of {col} for DataFrame {dfIdx + 1}\")\n",
    "      plt.xlabel(col)\n",
    "      plt.ylabel(\"Frequency\")\n",
    "      plt.legend(title=\"Label (Average Value)\")\n",
    "\n",
    "      # Show grid\n",
    "      plt.grid(axis=\"y\", alpha=0.75)\n",
    "\n",
    "      if not os.path.exists(f\"Figures/Histograms/{dfIdx + 1}\"):\n",
    "          os.makedirs(f\"Figures/Histograms/{dfIdx + 1}\")\n",
    "\n",
    "      sCol = re.sub(r\"[^\\w\\s]\", \"\", col)  # Remove non-alphanumeric characters\n",
    "      sCol = sCol.replace(\" \", \"_\")  # Replace spaces with underscores\n",
    "\n",
    "      plt.savefig(f\"Figures/Histograms/{dfIdx + 1}/Hist{dfIdx + 1}_{sCol}.png\")\n",
    "\n",
    "      # Close the figure to free up memory\n",
    "      plt.close()\n",
    "\n",
    "  print(\"Finished All Plotting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5p6JPLJCYVA"
   },
   "source": [
    "## I also create a function to scale and sample our data sets to make them less affected by outliers\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WYPrYK86BouJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pickle\n",
    "\n",
    "def saveIntrm(data, filename):\n",
    "  with open(filename, 'wb') as f:\n",
    "    pickle.dump(data, f)\n",
    "\n",
    "def loadIntrm(filename):\n",
    "  with open(filename, 'rb') as f:\n",
    "    return pickle.load(f)\n",
    "\n",
    "def scaleDS(df, cToDrop, overSample=False):\n",
    "  X = df.drop(columns=cToDrop)\n",
    "\n",
    "  # Handle NaN values and Infinite values\n",
    "  X = X[np.isfinite(X).all(axis=1)]\n",
    "  y = df[df.columns[-2]][X.index].values  # Align y with the index of X after dropping rows\n",
    "\n",
    "  X.dropna(inplace=True)\n",
    "  if np.isinf(X).sum().sum() > 0:\n",
    "    print(\"\\nWarning: Infinite values still present after replacement.\\n\")\n",
    "\n",
    "  scaler = StandardScaler()\n",
    "  X = scaler.fit_transform(X)\n",
    "\n",
    "  if isinstance(y, np.ndarray):\n",
    "    y = pd.Series(y)\n",
    "\n",
    "  if overSample:\n",
    "    unique = y.unique()\n",
    "    #print(f\"Unique Classes in y: {unique}\")\n",
    "\n",
    "    if len(unique) >= 2:\n",
    "        ros = RandomOverSampler()\n",
    "        X, y = ros.fit_resample(X, y)\n",
    "\n",
    "  if X.shape[0] != len(y):\n",
    "    print(f\"Dimension mismatch: X has {X.shape[0]} rows, y has {len(y)} entries.\")\n",
    "\n",
    "  data = np.hstack((X, np.reshape(y, (-1, 1))))\n",
    "\n",
    "  return data, X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "boBdjLfmCWSP"
   },
   "source": [
    "## After defining those functions, I am actually running them here and preparing for the use of our data\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5OBoEQ8HBS52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress a specific FutureWarning with a message matching the text\n",
    "warnings.filterwarnings(\"ignore\", message=\".*'DataFrame.swapaxes' is deprecated.*\")\n",
    "\n",
    "if (askPlot):\n",
    "  columns = [\"Total Fwd Packet\", \"Total Bwd packets\", \"Average Packet Size\"]\n",
    "  try:\n",
    "    plotData(columns, \"Time\", \"Number of Packets\", askGraph, labels)\n",
    "  except Exception as e:\n",
    "      # Handle any exceptions or errors\n",
    "      print(f\"An error occurred: {e}\")\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "colToDrop = [\"id\", \"Flow ID\", \"Src IP\", \"Dst IP\", \"Timestamp\"]\n",
    "\n",
    "# Prepare data for training, validation, and testing\n",
    "train = []\n",
    "valid = []\n",
    "test = []\n",
    "for df in dfList:\n",
    "  tr, va, te = np.split(df.sample(frac=1), [int(0.6 * len(df)), int(0.8 * len(df))])\n",
    "\n",
    "  train.append(tr)\n",
    "  valid.append(va)\n",
    "  test.append(te)\n",
    "\n",
    "trScale = []\n",
    "XTrain = []\n",
    "yTrain = []\n",
    "\n",
    "vaScale = []\n",
    "XValid = []\n",
    "yValid = []\n",
    "\n",
    "teScale = []\n",
    "XTest = []\n",
    "yTest = []\n",
    "count = 0\n",
    "\n",
    "# Scale values relative to mean\n",
    "for df in dfList:\n",
    "  # OverSample allows us to balance the amount of data if we want\n",
    "  trS, XTr, yTr = scaleDS(train[count], colToDrop, overSample=True)\n",
    "  vaS, XV, yV = scaleDS(valid[count], colToDrop, overSample=False)\n",
    "  teS, XTe, yTe = scaleDS(test[count], colToDrop, overSample=False)\n",
    "\n",
    "  # Save intermediate results to disk to free up RAM\n",
    "  saveIntrm(trS, f'train_scaled_{count}.pkl')\n",
    "  saveIntrm(XTr, f'X_train_{count}.pkl')\n",
    "  saveIntrm(yTr, f'y_train_{count}.pkl')\n",
    "\n",
    "  saveIntrm(vaS, f'validate_scaled_{count}.pkl')\n",
    "  saveIntrm(XV, f'X_validate_{count}.pkl')\n",
    "  saveIntrm(yV, f'y_validate_{count}.pkl')\n",
    "\n",
    "  saveIntrm(teS, f'test_scaled_{count}.pkl')\n",
    "  saveIntrm(XTe, f'X_test_{count}.pkl')\n",
    "  saveIntrm(yTe, f'y_test_{count}.pkl')\n",
    "\n",
    "  '''\n",
    "  trScale.append(trS)\n",
    "  XTrain.append(XTr)\n",
    "  yTrain.append(yTr)\n",
    "\n",
    "  vaScale.append(vaS)\n",
    "  XValid.append(XV)\n",
    "  yValid.append(yV)\n",
    "\n",
    "  teScale.append(teS)\n",
    "  XTest.append(XTe)\n",
    "  yTest.append(yTe)\n",
    "  '''\n",
    "\n",
    "  count += 1\n",
    "\n",
    "del train\n",
    "del valid\n",
    "del test\n",
    "del colToDrop\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LlmzmV20CUOC"
   },
   "source": [
    "## When we are finished with our plotting and preparation, I start with the Naive Bayes analysis\n",
    "****\n",
    "**Naive Bayes tries to predict our Labels by using the likelihood of seeing any given Label with respect to the prior Labels and the evidence we already have before us**\n",
    "\n",
    "**The original mathematical function of the Naive Bayes is given as:**\n",
    "$$\n",
    "P(C_{k} | x_{1}, x_{2}, ..., x_{n}) = \\frac{P(x_{1}, x_{2}, ..., x_{n} | C_{k}) * P(C_{k})}{P(x_{1}, x_{2}, ..., x_{n})}\n",
    "$$\n",
    "\n",
    "**We can then further derive it:**\n",
    "$$\n",
    "P(C_{k} | x_{1}, x_{2}, ..., x_{n}) \\propto P(x_{1}, x_{2}, ..., x_{n} | C_{k}) * P(C_{k})\n",
    "$$\n",
    "\n",
    "**Now, since we assume all the probabilities $x_{1}$, $x_{2}$, ..., $x_{n}$ are independent, we can just multiply the probabilities:**\n",
    "$$\n",
    "P(C_{k} | x_{1}, x_{2}, ..., x_{n}) \\propto (P(x_{1} | C_k) * P(x_{2} | C_k) * ... * P(x_{n} | C_k) * P(C_{k})\n",
    "$$\n",
    "\n",
    "**We can then rewrite this like:**\n",
    "$$\n",
    "P(C_{k} | x_{1}, x_{2}, ..., x_{n}) \\propto P(C_{k}) \\prod_{i=1}^{n}P(x_{i} | C_{k})\n",
    "$$\n",
    "\n",
    "****\n",
    "\n",
    "**Now, to predict the values in our dataset, we utilize the function:**\n",
    "\n",
    "*Note, argmax is the maximizing function. This is known as the MAP (Maximum A Posteriori)*\n",
    "$$\n",
    "\\hat{y} = argmax * P(C_{k}) \\prod_{i=1}^{n}P(x_{i} | C_{k})\n",
    "$$\n",
    "$$\n",
    "k  \\in \\{1, k\\}\n",
    "$$\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PzAOSD2UCjGj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Gaussian Naive Bayes Model...\n",
      "Finished Fitting, Beginning Prediciton...\n",
      "\n",
      "Gaussian Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89    316418\n",
      "           1       0.00      0.00      0.00       146\n",
      "           2       0.00      0.00      0.00       777\n",
      "           3       0.00      0.00      0.00     18920\n",
      "           4       0.00      0.00      0.00      1525\n",
      "           5       0.00      0.00      0.00        18\n",
      "           6       1.00      0.88      0.93     31711\n",
      "           7       0.00      0.00      0.00       108\n",
      "           8       0.00      0.00      0.00       377\n",
      "           9       1.00      0.81      0.90       704\n",
      "          10       0.00      0.00      0.00       788\n",
      "          11       1.00      0.08      0.15       353\n",
      "          12       0.00      0.00      0.00       834\n",
      "          13       1.00      1.00      1.00         2\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       1.00      0.25      0.40        12\n",
      "          16       1.00      0.86      0.92         7\n",
      "          17       1.00      0.01      0.01     14403\n",
      "          18       0.00      0.00      0.00     31850\n",
      "          19       0.00      0.00      0.00       627\n",
      "          20       1.00      1.00      1.00         6\n",
      "          21       0.00      0.00      0.00         9\n",
      "          22       1.00      1.00      1.00       250\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       1.00      0.50      0.67         2\n",
      "          25       0.00      0.00      0.00         6\n",
      "          26       1.00      1.00      1.00       139\n",
      "\n",
      "    accuracy                           0.82    419996\n",
      "   macro avg       0.44      0.31      0.33    419996\n",
      "weighted avg       0.72      0.82      0.75    419996\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2173"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB # Gaussian Naive Bayes\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from matplotlib.colors import LogNorm, Normalize # To make the Confusion Matrix Display easier to read\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "nbModel = GaussianNB()\n",
    "\n",
    "# Load data from disk\n",
    "for dfIdx in range(len(dfList)):\n",
    "  XTr = loadIntrm(f'X_train_{dfIdx}.pkl')\n",
    "  yTr = loadIntrm(f'y_train_{dfIdx}.pkl')\n",
    "  XTe = loadIntrm(f'X_test_{dfIdx}.pkl')\n",
    "  yTe = loadIntrm(f'y_test_{dfIdx}.pkl')\n",
    "\n",
    "  XTrain.append(XTr)\n",
    "  yTrain.append(yTr)\n",
    "  XTest.append(XTe)\n",
    "  yTest.append(yTe)\n",
    "\n",
    "del XTr\n",
    "del yTr\n",
    "del XTe\n",
    "gc.collect()\n",
    "\n",
    "# Concatenate all training data\n",
    "XTrainCom = np.concatenate(XTrain, axis=0)  # Combine all training features\n",
    "yTrainCom = np.concatenate(yTrain, axis=0)  # Combine all training labels\n",
    "\n",
    "del XTrain\n",
    "del yTrain\n",
    "gc.collect()\n",
    "\n",
    "# Fit the model using the combined training data\n",
    "print(\"Fitting Gaussian Naive Bayes Model...\")\n",
    "nbModel.fit(XTrainCom, yTrainCom)\n",
    "\n",
    "# Predict using the test sets\n",
    "print(\"Finished Fitting, Beginning Prediciton...\")\n",
    "yPredGNB = []\n",
    "for i in range(len(XTest)):\n",
    "    preds = nbModel.predict(XTest[i])\n",
    "    yPredGNB.append(preds)\n",
    "\n",
    "del nbModel\n",
    "gc.collect()\n",
    "\n",
    "# Flatten yPred if you want a single array\n",
    "yPredGNB = np.concatenate(yPredGNB)\n",
    "yTestCom = np.concatenate(yTest)\n",
    "\n",
    "print(\"\\nGaussian Classification Report:\\n\")\n",
    "print(classification_report(yTestCom, yPredGNB, zero_division=0))\n",
    "\n",
    "cm = confusion_matrix(yTestCom, yPredGNB, normalize='true')\n",
    "allLabels = pd.concat([df[\"Label\"] for df in dfList]).unique()\n",
    "le.fit(allLabels)\n",
    "yTrue = le.transform(yTestCom)\n",
    "reverseLabels = le.inverse_transform(np.unique(yTrue))\n",
    "maskedCM = np.ma.masked_where(cm == 0.00, cm)\n",
    "\n",
    "# Display the confusion matrix\n",
    "d = ConfusionMatrixDisplay(maskedCM, display_labels=reverseLabels)\n",
    "fig, axs = plt.subplots(figsize=(25, 25))\n",
    "\n",
    "# Define a colormap that will give zero values a light color\n",
    "cmap = plt.cm.inferno\n",
    "cmap.set_under('lightgray')\n",
    "\n",
    "# Plot the confusion matrix with LogNorm but allowing very light color for 0 values\n",
    "im = axs.imshow(maskedCM, interpolation='nearest', cmap=cmap, norm=LogNorm(vmin=0.1, vmax=cm.max()))\n",
    "\n",
    "# Add a colorbar and adjust its size to match the height of the plot\n",
    "cbar = fig.colorbar(im, ax=axs, fraction=0.046, pad=0.04)\n",
    "cbar.ax.tick_params(labelsize=15)\n",
    "\n",
    "# Customize the title and axis labels\n",
    "axs.set_title('Confusion Matrix for Gaussian Naive Bayes', fontsize=30, pad=20)\n",
    "axs.set_xlabel('Predicted label', fontsize=20, labelpad=20)\n",
    "axs.set_ylabel('True label', fontsize=20, labelpad=20)\n",
    "\n",
    "# Customize the tick labels and display class names\n",
    "axs.set_xticks(np.arange(len(reverseLabels)))\n",
    "axs.set_yticks(np.arange(len(reverseLabels)))\n",
    "axs.set_xticklabels(reverseLabels, fontsize=15, rotation=90)\n",
    "axs.set_yticklabels(reverseLabels, fontsize=15)\n",
    "\n",
    "# Rotate the tick labels and set their alignment\n",
    "plt.setp(axs.get_xticklabels(), ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "# Add spacing to ticks\n",
    "axs.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "axs.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "# Add text annotations inside the confusion matrix cells\n",
    "thresh = cm.max() / 2.  # Threshold for text color (white vs black)\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        axs.text(j, i, format(cm[i, j], '.2f'),\n",
    "                 ha=\"center\", va=\"center\",\n",
    "                 color=\"black\" if cm[i, j] > thresh else \"white\")\n",
    "\n",
    "# Adjust plot layout to ensure everything fits\n",
    "plt.subplots_adjust(left=0.2, right=0.8, top=0.9, bottom=0.1)\n",
    "\n",
    "if not os.path.exists(f\"Figures/Confusion_Matrix\"):\n",
    "    os.makedirs(f\"Figures/Confusion_Matrix\")\n",
    "\n",
    "plt.savefig(f\"Figures/Confusion_Matrix/GaussianNB.png\")\n",
    "\n",
    "del yPredGNB\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qTpNHnFCt4V"
   },
   "source": [
    "## After the Naive Bayes implementation, I move onto the Logistic Regression implementation\n",
    "****\n",
    "**Logistic Regression tries to predict our Labels by using the probability of any given point being above a given line so we can determine it as a Label**\n",
    "\n",
    "**We know that the slope of a regular regression line is given as:**\n",
    "$$\n",
    "\\hat{y} = mx + b\n",
    "$$\n",
    "\n",
    "**When using Logistic Regression, our line cant just be defined by $\\hat{y}$. We instead have to start with:**\n",
    "$$\n",
    "p = mx + b\n",
    "$$\n",
    "\n",
    "**Now, since $mx + b$ ranges from $-\\infty$ to $\\infty$ while probability has to be between 0 and 1, we set the \"odds\" of something being over or under our line:**\n",
    "$$\n",
    "\\ln {\\frac{p}{1-p}} = mx + b\n",
    "$$\n",
    "\n",
    "**To solve for p:**\n",
    "$$\n",
    "e^{\\ln {\\frac{p}{1-p}}} = e^{mx + b}\n",
    "$$\n",
    "$$\n",
    "\\frac{p}{1-p} = e^{mx + b}\n",
    "$$\n",
    "$$\n",
    "p = e^{mx + b}(1-p)\n",
    "$$\n",
    "$$\n",
    "p = e^{mx + b}-pe^{mx + b}\n",
    "$$\n",
    "$$\n",
    "p(1 + e^{mx + b}) = e^{mx + b}\n",
    "$$\n",
    "$$\n",
    "p = \\frac{e^{mx + b}}{1 + e^{mx + b}}\n",
    "$$\n",
    "\n",
    "**Since we want a numerator of 1:**\n",
    "$$\n",
    "p = \\frac{e^{mx + b}}{1 + e^{mx + b}} * \\frac{e^{-(mx + b)}}{e^{-(mx + b)}}\n",
    "$$\n",
    "$$\n",
    "p = \\frac{1}{1 + e^{-(mx + b)}}\n",
    "$$\n",
    "\n",
    "****\n",
    "**This gives us the special form similar to a Sigmoid function (S):**\n",
    "$$\n",
    "S(x) = \\frac{1}{1 + e^{-(x)}}\n",
    "$$\n",
    "\n",
    "**So we can rewrite our function as:**\n",
    "$$\n",
    "S(y) = \\frac{1}{1 + e^{-(y)}}\n",
    "$$\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression # Logistic Regression\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"Setting penalty=None will ignore the C and l1_ratio parameters\")\n",
    "\n",
    "def plot_logistic_results(history, penalty, regularization, dual):\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.plot(history['loss'], label='loss')\n",
    "    ax.plot(history['accuracy'], label='accuracy')\n",
    "    ax.set_xlabel('Iterations')\n",
    "    ax.set_ylabel('Metrics')\n",
    "    plt.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Create directory for saving figures if it doesn't exist\n",
    "    if not os.path.exists(\"Figures/Logistic_Regression\"):\n",
    "        os.makedirs(\"Figures/Logistic_Regression\")\n",
    "        \n",
    "    plt.savefig(f\"Figures/Logistic_Regression/Results_{penalty}_{regularization}_{dual}.png\")\n",
    "    plt.show()\n",
    "\n",
    "# This is a function i developed if you wanted to try and make the logistic regression even more accurate\n",
    "def trainLR(X_train, y_train, X_test, y_test, num_cores, penalties, regularizations, random_state):\n",
    "    best_model = None\n",
    "    best_val_score = 0\n",
    "    history_results = {'loss': [], 'accuracy': []}\n",
    "\n",
    "    # Suppress warnings during conversion and reshaping\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        \n",
    "        # Convert X_train and X_test to NumPy arrays if they are lists\n",
    "        X_train = np.array(X_train)\n",
    "        X_test = np.array(X_test)\n",
    "        \n",
    "        # Ensure X_train and X_test are 2D arrays\n",
    "        if len(X_train.shape) == 1:\n",
    "            X_train = X_train.reshape(-1, 1)\n",
    "        if len(X_test.shape) == 1:\n",
    "            X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "    \n",
    "    for penalty in penalties:\n",
    "        for reg in regularizations:\n",
    "            if penalty == 'l2':\n",
    "                for dual in [False, True]:\n",
    "                    print(f\"Penalty: {penalty}, Regularization: {reg}, Dual: {dual}\")\n",
    "                    lr_model = LogisticRegression(\n",
    "                        penalty=penalty, C=reg, \n",
    "                        solver='saga', dual=dual, random_state=random_state, n_jobs=(num_cores // 2 + 1)\n",
    "                    )\n",
    "\n",
    "                    # Fit the logistic regression model\n",
    "                    print(\"Fitting Model...\")\n",
    "                    lr_model.fit(X_train, y_train)\n",
    "\n",
    "                    # Evaluate on test set and collect metrics\n",
    "                    print(\"Finished Fitting, Evaluating Prediction and Metrics...\")\n",
    "                    y_pred = lr_model.predict(X_test)\n",
    "                    acc_score = np.mean(y_pred == y_test)\n",
    "                    history_results['accuracy'].append(acc_score)\n",
    "                    print(classification_report(y_test, y_pred))\n",
    "\n",
    "                    # Track best model\n",
    "                    if acc_score > best_val_score:\n",
    "                        best_val_score = acc_score\n",
    "                        best_model = lr_model\n",
    "\n",
    "                    history_results['loss'].append(lr_model.n_iter_[0])\n",
    "                    plot_logistic_results(history_results, penalty, reg, dual)\n",
    "            else:\n",
    "                print(f\"Penalty: {penalty}, Regularization: {reg}\")\n",
    "                lr_model = LogisticRegression(\n",
    "                    penalty=penalty, C=reg, \n",
    "                    solver='saga', random_state=random_state, n_jobs=(num_cores // 2 + 1)\n",
    "                )\n",
    "\n",
    "                # Fit the logistic regression model\n",
    "                print(\"Fitting Model...\")\n",
    "                lr_model.fit(X_train, y_train)\n",
    "\n",
    "                # Evaluate on test set and collect metrics\n",
    "                print(\"Finished Fitting, Evaluating Prediction and Metrics...\")\n",
    "                y_pred = lr_model.predict(X_test)\n",
    "                acc_score = np.mean(y_pred == y_test)\n",
    "                history_results['accuracy'].append(acc_score)\n",
    "                print(classification_report(y_test, y_pred))\n",
    "\n",
    "                # Track best model\n",
    "                if acc_score > best_val_score:\n",
    "                    best_val_score = acc_score\n",
    "                    best_model = lr_model\n",
    "\n",
    "                history_results['loss'].append(lr_model.n_iter_[0])\n",
    "                plot_logistic_results(history_results, penalty, reg, None)\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "HFOW_eP9Cjjz",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Logistic Regression Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Fitting, Beginning Prediciton...\n",
      "\\Logistic Regression Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00    316418\n",
      "           1       0.07      0.99      0.13       146\n",
      "           2       1.00      1.00      1.00       777\n",
      "           3       0.98      1.00      0.99     18920\n",
      "           4       0.86      0.99      0.92      1525\n",
      "           5       0.09      1.00      0.16        18\n",
      "           6       1.00      1.00      1.00     31711\n",
      "           7       0.90      1.00      0.95       108\n",
      "           8       0.89      0.99      0.94       377\n",
      "           9       1.00      1.00      1.00       704\n",
      "          10       0.98      0.99      0.99       788\n",
      "          11       0.98      1.00      0.99       353\n",
      "          12       1.00      1.00      1.00       834\n",
      "          13       0.67      1.00      0.80         2\n",
      "          14       0.14      1.00      0.25         1\n",
      "          15       0.38      0.67      0.48        12\n",
      "          16       0.55      0.86      0.67         7\n",
      "          17       0.99      0.98      0.99     14403\n",
      "          18       0.99      1.00      1.00     31850\n",
      "          19       0.99      1.00      1.00       627\n",
      "          20       0.33      1.00      0.50         6\n",
      "          21       0.53      1.00      0.69         9\n",
      "          22       0.92      0.98      0.95       250\n",
      "          23       0.18      1.00      0.30         3\n",
      "          24       0.22      1.00      0.36         2\n",
      "          25       0.86      1.00      0.92         6\n",
      "          26       0.81      0.99      0.89       139\n",
      "\n",
      "    accuracy                           0.99    419996\n",
      "   macro avg       0.72      0.98      0.77    419996\n",
      "weighted avg       1.00      0.99      0.99    419996\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalties = [None, 'l1', 'l2', 'elasticnet']\n",
    "regularizations = [0.85, 1, 1.15]\n",
    "random_state = 1\n",
    "\n",
    "# bestLRModel = trainLR(XTrainCom, yTrainCom, XTest, yTestCom, askCPU, penalties, regularizations, random_state)\n",
    "\n",
    "# -2 for the number of jobs causes the program to use all but 1 CPU cores\n",
    "lrModel = LogisticRegression('l2', solver='saga', random_state=random_state, n_jobs=askCPU)\n",
    "\n",
    "print(\"Fitting Logistic Regression Model...\")\n",
    "lrModel.fit(XTrainCom, yTrainCom)\n",
    "\n",
    "print(\"Finished Fitting, Beginning Prediciton...\")\n",
    "yPred = []\n",
    "for i in range(len(XTest)):\n",
    "    preds = lrModel.predict(XTest[i])\n",
    "    yPred.append(preds)\n",
    "\n",
    "yPred = np.concatenate(yPred)\n",
    "yTestCom = np.concatenate(yTest)\n",
    "\n",
    "# del bestLRModel\n",
    "gc.collect()\n",
    "\n",
    "print(\"\\Logistic Regression Classification Report:\\n\")\n",
    "print(classification_report(yTestCom, yPred))\n",
    "\n",
    "cm = confusion_matrix(yTestCom, yPred, normalize='true')\n",
    "maskedCM = np.ma.masked_where(cm == 0.00, cm)\n",
    "\n",
    "# Display the confusion matrix\n",
    "d = ConfusionMatrixDisplay(maskedCM, display_labels=reverseLabels)\n",
    "fig, axs = plt.subplots(figsize=(25, 25))\n",
    "\n",
    "# Define a colormap that will give zero values a light color\n",
    "cmap = plt.cm.plasma\n",
    "cmap.set_under('mediumpurple')\n",
    "\n",
    "# Plot the confusion matrix with LogNorm but allowing very light color for 0 values\n",
    "im = axs.imshow(maskedCM, interpolation='nearest', cmap=cmap, norm=LogNorm(vmin=0.1, vmax=cm.max()))\n",
    "\n",
    "# Add a colorbar and adjust its size to match the height of the plot\n",
    "cbar = fig.colorbar(im, ax=axs, fraction=0.046, pad=0.04)\n",
    "cbar.ax.tick_params(labelsize=15)\n",
    "\n",
    "# Customize the title and axis labels\n",
    "axs.set_title('Confusion Matrix for Logistic Regression', fontsize=30, pad=20)\n",
    "axs.set_xlabel('Predicted label', fontsize=20, labelpad=20)\n",
    "axs.set_ylabel('True label', fontsize=20, labelpad=20)\n",
    "\n",
    "# Customize the tick labels and display class names\n",
    "axs.set_xticks(np.arange(len(reverseLabels)))\n",
    "axs.set_yticks(np.arange(len(reverseLabels)))\n",
    "axs.set_xticklabels(reverseLabels, fontsize=15, rotation=90)\n",
    "axs.set_yticklabels(reverseLabels, fontsize=15)\n",
    "\n",
    "# Rotate the tick labels and set their alignment\n",
    "plt.setp(axs.get_xticklabels(), ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "# Add spacing to ticks\n",
    "axs.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "axs.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "# Add text annotations inside the confusion matrix cells\n",
    "thresh = cm.max() / 2.  # Threshold for text color (white vs black)\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        axs.text(j, i, format(cm[i, j], '.2f'),\n",
    "                 ha=\"center\", va=\"center\",\n",
    "                 color=\"black\" if cm[i, j] > thresh else \"white\")\n",
    "\n",
    "# Adjust plot layout to ensure everything fits\n",
    "plt.subplots_adjust(left=0.2, right=0.8, top=0.9, bottom=0.1)\n",
    "\n",
    "if not os.path.exists(f\"Figures/Confusion_Matrix\"):\n",
    "    os.makedirs(f\"Figures/Confusion_Matrix\")\n",
    "\n",
    "plt.savefig(f\"Figures/Confusion_Matrix/LogRegression.png\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTlClV8MCuXV"
   },
   "source": [
    "## After going over Naive Bayes and Logistic Regression, we start by creating a loss-plotting function and an accuracy-plotting function\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fd8jUwwPCyCa"
   },
   "outputs": [],
   "source": [
    "def plot_hist(history, numNode, dropProb, learnRate, batchSize):\n",
    "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "  ax1.plot(history.history['loss'], label='loss')\n",
    "  ax1.plot(history.history['val_loss'], label='val_loss')\n",
    "  ax1.set_xlabel('Epoch')\n",
    "  ax1.set_ylabel('Binary Cross Entropy')\n",
    "  ax1.grid(True)\n",
    "\n",
    "  ax2.plot(history.history['accuracy'], label='accuracy')\n",
    "  ax2.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "  ax2.set_xlabel('Epoch')\n",
    "  ax2.set_ylabel('Accuracy')\n",
    "  plt.legend()\n",
    "  ax2.grid(True)\n",
    "\n",
    "  if not os.path.exists(\"Figures/Neural_Network\"):\n",
    "    os.makedirs(\"Figures/Neural_Network\")\n",
    "    plt.savefig(f\"Figures/Neural_Network/Loss_And_Acc_{numNode}_{dropProb}_{learnRate}_{batchSize}.png\")\n",
    "\n",
    "  #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUwKC8nvCzG6"
   },
   "source": [
    "## After defining those functions, we will start on the Neural Network\n",
    "****\n",
    "**A neural network has a bunch of nodes called neurons.**\n",
    "\n",
    "**In a neural network, we have a bunch of input features $x_1, x_2, ..., x_n$ to process.**\n",
    "\n",
    "**We sum all of these inputs with their respective weights, which then goes into each neuron. This neuron can have a specified bias applied to it to shift the values somewhat.**\n",
    "\n",
    "**The output of the weighted input values being passed into the neurons with the bias all gets passed to the activation function. After applying the activation function, we get our output prediction.**\n",
    "\n",
    "**Now, I wasn't actually able to run the Neural Network(s) in their entirety because it takes way too long. For a single model to get trained on the dataset as I have it now, it would take somewhere from 3 to 5 hours on just 25 epochs. The functionality is their, though, as I was able to see what a couple of the models looked like.**\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "VO9HIrNCCLOJ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def trainNN(XTrainSet, yTrainSet, numNodes, dropoutProb, learningRate, batchSize, epochs):\n",
    "  # Linearlly stack layers as a model\n",
    "  nnModel = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(numNodes, activation='relu', input_shape=(86,)),    # First layer uses RELU and 32 nodes\n",
    "    tf.keras.layers.Dropout(dropoutProb),\n",
    "    tf.keras.layers.Dense(numNodes, activation='relu'),                       # Next layer is the same\n",
    "    tf.keras.layers.Dropout(dropoutProb),\n",
    "      \n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')                      # Last layer uses Signmoid function\n",
    "  ])\n",
    "\n",
    "  # Compile the Neural Network with the Adam activation function using binary cross entropy as our loss\n",
    "  # We will also have another metric stored for us, accuracy\n",
    "  print(\"Compiling Neural Network...\")\n",
    "  nnModel.compile(optimizer=tf.keras.optimizers.Adam(learningRate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy']\n",
    "  )\n",
    "\n",
    "  print(\"Finished Compiling, Fitting Neural Network Model...\")\n",
    "  history = nnModel.fit(\n",
    "    XTrainCom, yTrainCom,\n",
    "    epochs=epochs, batch_size=batchSize,\n",
    "    validation_split=0.2, verbose=0\n",
    "  )\n",
    "\n",
    "  return nnModel, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXUaJIGKeJ59"
   },
   "source": [
    "## After defining the Neural Network function, we can use it with customized values to see what gets the best results\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pxqgaTfDeKLr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 4, Drop Probability: 0, Learn Rate: 0.005, Batch Size: 16\n",
      "Compiling Neural Network...\n",
      "Finished Compiling, Fitting Neural Network Model...\n"
     ]
    }
   ],
   "source": [
    "for dfIdx in range(len(dfList)):\n",
    "  XVa = loadIntrm(f'X_validate_{dfIdx}.pkl')\n",
    "  yVa = loadIntrm(f'y_validate_{dfIdx}.pkl')\n",
    "\n",
    "  XValid.append(XVa)\n",
    "  yValid.append(yVa)\n",
    "\n",
    "del XVa\n",
    "del yVa\n",
    "gc.collect()\n",
    "\n",
    "XValidCom = np.concatenate(XValid)\n",
    "yValidCom = np.concatenate(yValid)\n",
    "\n",
    "del XValid\n",
    "del yValid\n",
    "gc.collect()\n",
    "\n",
    "leastValLoss = float('inf')\n",
    "leastLossModel = None\n",
    "\n",
    "epoch = 25\n",
    "for numNode in [4, 8, 16, 32, 64]:\n",
    "  for dropProb in [0, 0.1, 0.2]:\n",
    "    for learnRate in [0.005, 0.001, 0.1]:\n",
    "      for batchSize in [16, 32, 64, 128]:\n",
    "        print(f\"Nodes: {numNode}, Drop Probability: {dropProb}, Learn Rate: {learnRate}, Batch Size: {batchSize}\")\n",
    "        model, history = trainNN(XTrainCom, yTrainCom, numNode, dropProb, learnRate, batchSize, epoch)\n",
    "        print(\"Finished Fitting, Plotting Data...\")\n",
    "        plot_hist(history, numNode, dropProb, learnRate, batchSize)\n",
    "\n",
    "        valLoss = model.evaluate(XValidCom, yValidCom)[0]\n",
    "        if valLoss < leastValLoss:\n",
    "          leastValLoss = valLoss\n",
    "          leastLossModel = model\n",
    "\n",
    "yPr = leastLossModel.predict(XTest)\n",
    "yPr = (yPr > 0.5).astype(int).reshape(-1,)\n",
    "yPr = np.concatenate(yPr)\n",
    "print(classification_report(yTestCom, yPr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUvW2YHiFIrE"
   },
   "source": [
    "## After finishing the predictions, we zip the Figures folder and provide a download link.\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yTJq6AHqFI1O"
   },
   "outputs": [],
   "source": [
    "if isUsingColab:\n",
    "    from IPython.display import FileLink\n",
    "    \n",
    "    # Create a zip archive of the Figures folder\n",
    "    shutil.make_archive(\"Figures\", 'zip', \"Figures\")\n",
    "    \n",
    "    # Provide the download link for the zipped figures\n",
    "    FileLink(\"Figures.zip\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
